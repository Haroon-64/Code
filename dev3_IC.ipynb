{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "NUM_FILES = 100\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = (300,400)  # len, width\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_folder, num_files=None):\n",
    "    \"\"\"\n",
    "    Read Spectrograms data from .npy files in the specified data folder.\n",
    "\n",
    "    Parameters:\n",
    "    - data_folder (str): Path to the main data folder containing 'train' and 'test' subfolders.\n",
    "    - num_files (int or None): Number of files to read from each subfolder. If None, all files will be read.\n",
    "\n",
    "    Returns:\n",
    "    - train (array[Tuple[np.ndarray, np.ndarray]]): List of tuples containing train EEG data.\n",
    "    - test (array[Tuple[np.ndarray, np.ndarray]]): List of tuples containing test EEG data.\n",
    "    - train_labels (pd.DataFrame): DataFrame containing train labels.\n",
    "    - test_labels (pd.DataFrame): DataFrame containing test labels.\n",
    "    \"\"\"\n",
    "    train_spec_folder = os.path.join(data_folder, 'train_spectrograms')\n",
    "    test_spec_folder = os.path.join(data_folder, 'test_spectrograms')\n",
    "\n",
    "    def read_npy_folder(folder_path, n_files=None):\n",
    "        arrays = []\n",
    "        files_to_read = os.listdir(folder_path)[:n_files] if n_files else os.listdir(folder_path)\n",
    "        for file in files_to_read:\n",
    "            if file.endswith('.npy'):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                array = np.load(file_path)\n",
    "                arrays.append(array)\n",
    "        print(f\"Read {len(arrays)} files from {folder_path}.\")\n",
    "        return arrays\n",
    "\n",
    "    # Read EEG data\n",
    "    train_spec = read_npy_folder(train_spec_folder, num_files)\n",
    "    test_spec = read_npy_folder(test_spec_folder)\n",
    "\n",
    "    train_labels = pd.read_csv(os.path.join(data_folder, 'train.csv'), nrows=num_files)\n",
    "    test_labels = pd.read_csv(os.path.join(data_folder, 'test.csv'))\n",
    "\n",
    "    return train_spec, test_spec, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 100 files from data/npy_data/npy_data/train_spectrograms.\n",
      "Read 1 files from data/npy_data/npy_data/test_spectrograms.\n"
     ]
    }
   ],
   "source": [
    "train,_test,train_labels,_test_labels = read_data('data/npy_data/npy_data',num_files=NUM_FILES)\n",
    "labels = pd.read_csv('train.csv', nrows=NUM_FILES)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train, train_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels_train = label_encoder.fit_transform(y_train[:, 8])\n",
    "encoded_labels_val = label_encoder.fit_transform(y_val[:, 8])\n",
    "\n",
    "y_train = torch.nn.functional.one_hot(torch.tensor(encoded_labels_train), num_classes=NUM_CLASSES).float()\n",
    "y_val = torch.nn.functional.one_hot(torch.tensor(encoded_labels_val), num_classes=NUM_CLASSES).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 401)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 75 * 100, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = Image.fromarray(image)\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel(num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),  \n",
    "    transforms.ToTensor(),       \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = ImageDataset(X_val, y_val, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel(num_classes=NUM_CLASSES)\n",
    "criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Mini-batch 10] Loss: -126.189\n",
      "[Epoch 2, Mini-batch 10] Loss: -2007.984\n",
      "[Epoch 3, Mini-batch 10] Loss: -13623.144\n",
      "[Epoch 4, Mini-batch 10] Loss: -57942.819\n",
      "[Epoch 5, Mini-batch 10] Loss: -190910.945\n",
      "[Epoch 6, Mini-batch 10] Loss: -514265.206\n",
      "[Epoch 7, Mini-batch 10] Loss: -1222846.156\n",
      "[Epoch 8, Mini-batch 10] Loss: -2543451.475\n",
      "[Epoch 9, Mini-batch 10] Loss: -4870851.000\n",
      "[Epoch 10, Mini-batch 10] Loss: -8693399.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m labels_one_hot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(torch\u001b[38;5;241m.\u001b[39margmax(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), num_classes\u001b[38;5;241m=\u001b[39mNUM_CLASSES)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels_one_hot)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \n\u001b[1;32m     11\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        labels_one_hot = torch.nn.functional.one_hot(torch.argmax(labels, dim=1), num_classes=NUM_CLASSES).float()\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            print(f'[Epoch {epoch + 1}, Mini-batch {i + 1}] Loss: {running_loss / 10:.3f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval() \n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            labels_one_hot = torch.nn.functional.one_hot(torch.argmax(labels, dim=1), num_classes=NUM_CLASSES).float()\n",
    "            loss = criterion(outputs, labels_one_hot)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.argmax(labels_one_hot, dim=1)).sum().item()\n",
    "\n",
    "\n",
    "print(f'Epoch {epoch + 1}/{EPOCHS}, Validation Loss: {val_loss / len(val_loader):.4f}, Accuracy: {(correct / total) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_parquet_to_npy(input_folder, output_folder):\n",
    "#     npy_output_folder = os.path.join(output_folder, 'npy_data')\n",
    "    \n",
    "#     # Ensure the output directory exists\n",
    "#     os.makedirs(npy_output_folder, exist_ok=True)\n",
    "    \n",
    "#     for root, dirs, files in os.walk(input_folder):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.parquet'):\n",
    "#                 parquet_path = os.path.join(root, file)\n",
    "#                 df = pd.read_parquet(parquet_path)\n",
    "#                 eeg_data = df.to_numpy()\n",
    "#                 relative_path = os.path.relpath(parquet_path, input_folder)\n",
    "                \n",
    "#                 # Create the corresponding directory structure in the npy_data folder\n",
    "#                 output_subfolder = os.path.join(npy_output_folder, os.path.dirname(relative_path))\n",
    "#                 os.makedirs(output_subfolder, exist_ok=True)\n",
    "#                 np.save(os.path.join(output_subfolder, file.replace('.parquet', '.npy')), eeg_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
