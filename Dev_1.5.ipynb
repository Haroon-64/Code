{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T15:45:24.276045187Z",
     "start_time": "2024-01-29T15:45:24.241753058Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Flatten, Dropout,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from scipy import signal\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:17.045634291Z",
     "start_time": "2024-01-28T12:10:17.001058386Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(data_folder, num_files=None):\n",
    "    \"\"\"\n",
    "    Read EEG data from .npy files in the specified data folder.\n",
    "\n",
    "    Parameters:\n",
    "    - data_folder (str): Path to the main data folder containing 'train' and 'test' subfolders.\n",
    "    - num_files (int or None): Number of files to read from each subfolder. If None, all files will be read.\n",
    "\n",
    "    Returns:\n",
    "    - train (List[Tuple[np.ndarray, np.ndarray]]): List of tuples containing train EEG data.\n",
    "    - test (List[Tuple[np.ndarray, np.ndarray]]): List of tuples containing test EEG data.\n",
    "    - train_labels (pd.DataFrame): DataFrame containing train labels.\n",
    "    - test_labels (pd.DataFrame): DataFrame containing test labels.\n",
    "    \"\"\"\n",
    "    train_eeg_folder = os.path.join(data_folder, 'npy_train')\n",
    "    test_eeg_folder = os.path.join(data_folder, 'npy_test')\n",
    "\n",
    "\n",
    "    def read_npy_folder(folder_path, n_files=None):\n",
    "        arrays = []\n",
    "        files_to_read = os.listdir(folder_path)[:n_files] if n_files else os.listdir(folder_path)\n",
    "        for file in files_to_read:\n",
    "            if file.endswith('.npy'):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                array = np.load(file_path)\n",
    "                arrays.append(array)\n",
    "        print(f\"Read {len(arrays)} files from {folder_path}.\")\n",
    "        return arrays\n",
    "\n",
    "    # Read EEG data\n",
    "    train_eeg = read_npy_folder(train_eeg_folder, num_files)\n",
    "    test_eeg = read_npy_folder(test_eeg_folder)\n",
    "\n",
    "    # Interpolate NaN values (if needed)\n",
    "    train_eeg = [np.nan_to_num(array) for array in train_eeg]\n",
    "\n",
    "    # Combine data into tuples\n",
    "    train_labels = pd.read_csv('train.csv', nrows=num_files)\n",
    "    test_labels = pd.read_csv('test.csv')\n",
    "\n",
    "    return train_eeg, test_eeg, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:17.069997229Z",
     "start_time": "2024-01-28T12:10:17.046114962Z"
    }
   },
   "outputs": [],
   "source": [
    "def single_vis(f, visualization_type):\n",
    "    \"\"\"\n",
    "    Visualize single EEG channels or Spectrogram from the provided DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - f (pd.DataFrame): The DataFrame containing the data to be visualized.\n",
    "    - visualization_type (str): Specify the type of visualization: 'eeg' for EEG channels or 'spectrogram' for Spectrogram.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If an invalid `visualization_type` is provided.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    if visualization_type == 'eeg':\n",
    "        channels_to_exclude = []\n",
    "        title = 'EEG Channels Visualization'\n",
    "        \n",
    "        eeg_channels = [column for column in f.columns if column not in channels_to_exclude]\n",
    "        plt.figure(figsize=(40, 10))\n",
    "        \n",
    "        # Calculate the offset for each channel based on the maximum amplitude\n",
    "        max_amplitude = f[eeg_channels].max().max()\n",
    "        channel_offset = max_amplitude * 1.2  # Adjust the multiplier as needed\n",
    "        \n",
    "        for i, column in enumerate(eeg_channels):\n",
    "            y_values = f[column] + i * channel_offset\n",
    "            plt.plot(f.index, y_values, label=column)\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    elif visualization_type == 'spectrogram':\n",
    "        channels_to_exclude = ['time']\n",
    "        title = 'Spectrogram Visualization'\n",
    "        \n",
    "        spectrogram_channels = [column for column in f.columns if column not in channels_to_exclude]\n",
    "        plt.figure(figsize=(40, 10))\n",
    "        \n",
    "        combined_spectrogram = np.zeros((len(f), len(spectrogram_channels)))\n",
    "        for i, column in enumerate(spectrogram_channels):\n",
    "            combined_spectrogram[:, i] = f[column].values\n",
    "        \n",
    "        plt.imshow(combined_spectrogram.T, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Channel')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Invalid visualization type. Use 'eeg' or 'spectrogram'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:17.081755310Z",
     "start_time": "2024-01-28T12:10:17.061765171Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_length = 100\n",
    "num_features = 32\n",
    "desired_length = 100  \n",
    "num_frequency_bins = 32  \n",
    "num_classes = 6 \n",
    "num_files = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:17.112649517Z",
     "start_time": "2024-01-28T12:10:17.077069883Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_eeg(X_train_eeg, target_shape=(desired_length, num_features)):\n",
    "    eeg_array = np.array(X_train_eeg)[:desired_length, :num_features].astype(np.float32)\n",
    "    return eeg_array\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_spectrogram(spectrogram_df, target_shape=(desired_length, num_frequency_bins)):\n",
    "    spec_array = np.array(spectrogram_df)[:target_shape[0], :target_shape[1]].astype(np.float32)\n",
    "    return spec_array\n",
    "\n",
    "def create_model(input_shape_eeg, input_shape_spectrogram, num_classes=6):\n",
    "    \"\"\"Create a multi-input, multi-output model for\n",
    "    EEG and Spectrogram data.\n",
    "\n",
    "    Args:\n",
    "        input_shape_eeg : shape of one EEG sample\n",
    "        input_shape_spectrogram : shape of one Spectrogram sample\n",
    "        num_classes : 6 for seizure, lpd, gpd, lrda, grda, other\n",
    "\n",
    "    Returns:\n",
    "        keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(units=64, input_shape=input_shape_eeg[1:], return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        tf.keras.layers.LSTM(units=64),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(6, activation='softmax')\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch > 0:\n",
    "        return lr * 0.9\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:24.748826349Z",
     "start_time": "2024-01-28T12:10:17.105073429Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 100 files from data/npy_train.\n",
      "Read 1 files from data/npy_test.\n"
     ]
    }
   ],
   "source": [
    "train,test,train_labels,test_labels = read_data('data',num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:24.791865311Z",
     "start_time": "2024-01-28T12:10:24.750681819Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train_labels, test_size=0.2, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= np.concatenate(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of examples you want\n",
    "num_examples = int(num_files * 0.8)\n",
    " \n",
    "# Calculate the number of samples per example\n",
    "samples_per_example = X_train.shape[0] // num_examples\n",
    "\n",
    "# Initialize a list to store the split examples\n",
    "X_train_split = []\n",
    "\n",
    "# Split X_train\n",
    "for i in range(num_examples):\n",
    "    start_index = i * samples_per_example\n",
    "    end_index = (i + 1) * samples_per_example\n",
    "    example = X_train[start_index:end_index]\n",
    "    X_train_split.append(example)\n",
    "\n",
    "# Convert the list of examples into a numpy array\n",
    "X_train_split = np.array(X_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 13625, 20)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:25.687317448Z",
     "start_time": "2024-01-28T12:10:25.652011627Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:25.687953310Z",
     "start_time": "2024-01-28T12:10:25.654741096Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = y_train[:, 8]\n",
    "\n",
    "# Encoding labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = to_categorical(encoded_labels, num_classes=num_classes)\n",
    "\n",
    "# Convert labels to float32\n",
    "y_train = one_hot_labels.astype('float32')\n",
    "\n",
    "# Convert other columns to numeric values\n",
    "for col_index in range(y_train.shape[1]):\n",
    "    # Skip label column as it has already been encoded\n",
    "    if col_index == 8:\n",
    "        continue\n",
    "    \n",
    "    # Convert each element in the column to a numeric value\n",
    "    y_train[:, col_index] = np.array([float(val) if isinstance(val, str) and '.' in val else int(val) for val in y_train[:, col_index]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:25.847117728Z",
     "start_time": "2024-01-28T12:10:25.707765395Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_eeg = X_train_split.astype(np.float32)\n",
    "\n",
    "\n",
    "input_shape_eeg = X_train_eeg.shape#Shape of one EEG sample\n",
    "\n",
    "num_classes = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:25.848243519Z",
     "start_time": "2024-01-28T12:10:25.748385010Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_train_eeg)):\n",
    "    if np.any(np.isnan(X_train_eeg[i])):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:10:25.850031422Z",
     "start_time": "2024-01-28T12:10:25.792225636Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(X_train_eeg.dtype)\n",
    "# print(X_train_spectrogram.dtype)\n",
    "# print(y_train.dtype)\n",
    "# print(input_shape_eeg[1:])\n",
    "# print(input_shape_spectrogram[1:])\n",
    "# print(np.any(np.isnan(X_train_eeg)))\n",
    "# print(np.any(np.isnan(X_train_spectrogram)))\n",
    "# print(np.any(np.isinf(X_train_eeg)))\n",
    "# print(np.any(np.isinf(X_train_spectrogram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_eeg: (80, 13625, 20)\n",
      "Shape of y_train: (80, 6)\n",
      "(80, 13625, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train_eeg:\", X_train_eeg.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(input_shape_eeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:11:29.927681140Z",
     "start_time": "2024-01-28T12:11:26.450167072Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(input_shape_eeg, 6)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss = tf.keras.losses.KLDivergence(), metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_eeg, y_train, epochs=10, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:11:46.327154236Z",
     "start_time": "2024-01-28T12:11:46.275300051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 13625, 64)         21760     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 13625, 64)         256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13625, 64)         0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57574 (224.90 KB)\n",
      "Trainable params: 57318 (223.90 KB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_test = np.concatenate(X_test, axis=0)\n",
    "# num_examples_test = int(num_files * 0.2)  \n",
    "# samples_per_example_test = X_test.shape[0] // num_examples_test\n",
    "# X_test_split = []\n",
    "# for i in range(num_examples_test):\n",
    "#     start_index = i * samples_per_example_test\n",
    "#     end_index = (i + 1) * samples_per_example_test\n",
    "#     example = X_test[start_index:end_index]\n",
    "#     X_test_split.append(example)\n",
    "# X_test_split = np.array(X_test_split)\n",
    "# X_test_eeg = X_test_split.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = y_test.iloc[:, 8]\n",
    "encoded_labels_test = label_encoder.transform(labels_test)\n",
    "one_hot_labels_test = to_categorical(encoded_labels_test, num_classes=num_classes)\n",
    "y_test = one_hot_labels_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:11:48.407838814Z",
     "start_time": "2024-01-28T12:11:48.259725983Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_eeg = np.array([preprocess_eeg(item) for item in X_test])\n",
    "y_pred = model.predict(X_test_eeg)\n",
    "\n",
    "eeg_ids_test = [X_test[i][0].index[0] for i in range(len(X_test))]\n",
    "\n",
    "output_df = pd.DataFrame({\n",
    "    'eeg_id': eeg_ids_test,\n",
    "    'seizure_vote': y_pred[:, 0],\n",
    "    'lpd_vote': y_pred[:, 1],\n",
    "    'gpd_vote': y_pred[:, 2],\n",
    "    'lrda_vote': y_pred[:, 3],\n",
    "    'grda_vote': y_pred[:, 4],\n",
    "    'other_vote': y_pred[:, 5]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:14:00.286844403Z",
     "start_time": "2024-01-28T12:14:00.238849046Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:13:19.164095602Z",
     "start_time": "2024-01-28T12:13:19.114231189Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_df['predicted_class'] = output_df.iloc[:, 1:].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:13:21.267551005Z",
     "start_time": "2024-01-28T12:13:21.234074335Z"
    }
   },
   "outputs": [],
   "source": [
    "print(output_df[['eeg_id', 'predicted_class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T12:13:28.524750635Z",
     "start_time": "2024-01-28T12:13:28.515955872Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Shape of X_test_eeg:\", X_test_eeg.shape)\n",
    "print(\"NaN values in X_test_eeg:\", np.isnan(X_test_eeg).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)\n",
    "labelst = y_test[:, 8]\n",
    "\n",
    "# Encoding labels using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labelst)\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = to_categorical(encoded_labels, num_classes=num_classes)\n",
    "\n",
    "# Convert labels to float32\n",
    "y_test = one_hot_labels.astype('float32')\n",
    "\n",
    "# Convert other columns to numeric values\n",
    "for col_index in range(y_test.shape[1]):\n",
    "    # Skip label column as it has already been encoded\n",
    "    if col_index == 8:\n",
    "        continue\n",
    "    \n",
    "    # Convert each element in the column to a numeric value\n",
    "    y_test[:, col_index] = np.array([float(val) if isinstance(val, str) and '.' in val else int(val) for val in y_test[:, col_index]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-28T12:10:29.701959173Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
